version: '3.8'
services:

  # This "container" is a workaround to pre-create topics
  # kafka-setup:
  #   image: linkedin/datahub-kafka-setup
  #   environment:
  #     KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
  #     KAFKA_BOOTSTRAP_SERVER=broker:29092

  #     # Configure the topics that are created by kafka-setup
  #     # Make sure these names are consistent across the whole deployment
  #     # METADATA_AUDIT_EVENT_NAME=MetadataAuditEvent_v4
  #     # METADATA_CHANGE_EVENT_NAME=MetadataChangeEvent_v4
  #     # FAILED_METADATA_CHANGE_EVENT_NAME=FailedMetadataChangeEvent_v4
  #     # PLATFORM_EVENT_TOPIC_NAME=PlatformEvent_v1
  #     # DATAHUB_USAGE_EVENT_NAME=DataHubUsageEvent_v1
  #     # PARTITIONS=1
  #     # REPLICATION_FACTOR=1

  #     # Configure for an SSL-Connection to Kafka
  #     # KAFKA_PROPERTIES_SECURITY_PROTOCOL=SSL
  #     # KAFKA_PROPERTIES_SSL_KEYSTORE_LOCATION=
  #     # KAFKA_PROPERTIES_SSL_KEYSTORE_PASSWORD=
  #     # KAFKA_PROPERTIES_SSL_KEY_PASSWORD=
  #     # KAFKA_PROPERTIES_SSL_TRUSTSTORE_LOCATION=
  #     # KAFKA_PROPERTIES_SSL_TRUSTSTORE_PASSWORD=
  #     # KAFKA_PROPERTIES_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM=

  #     # Uncomment to disable persistence of client-side analytics events
  #     # DATAHUB_ANALYTICS_ENABLED=false

  # This "container" is a workaround to pre-create search indices
  elasticsearch-setup:
    image: linkedin/datahub-elasticsearch-setup:637b540
    environment:
      ELASTICSEARCH_HOST: elasticsearch
      ELASTICSEARCH_PORT: 9200
      ELASTICSEARCH_PROTOCOL: http
      # DATAHUB_ANALYTICS_ENABLED=false
    networks:
      - local

networks:
  local:
    external: true
